{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"densedepth.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyN68qBawGvQHpG2Q1/6ZNfY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"f2YeG2x2bBEZ","executionInfo":{"status":"ok","timestamp":1620239022830,"user_tz":240,"elapsed":982,"user":{"displayName":"STANISLAV SOTNIKOV","photoUrl":"","userId":"10330785928170966351"}}},"source":["import tensorflow as tf\n","import tensorflow.keras.backend as K\n","\n","from tensorflow.keras.layers import Conv2D, UpSampling2D, LeakyReLU, Concatenate\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import Model\n","from tensorflow.keras.applications import DenseNet169"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ospam88JetdR"},"source":["## Model Architecture ##"]},{"cell_type":"code","metadata":{"id":"edwkaf2Ke4x_","executionInfo":{"status":"ok","timestamp":1620239022834,"user_tz":240,"elapsed":974,"user":{"displayName":"STANISLAV SOTNIKOV","photoUrl":"","userId":"10330785928170966351"}}},"source":["class UpscaleBlock(Model):\n","    def __init__(self, filters, name):\n","        super(UpscaleBlock, self).__init__()\n","        self.up = UpSampling2D(size=(2, 2), interpolation='bilinear', name=name + '_upsampling2d')\n","        self.concat = Concatenate(name=name + '_concat')  # Skip connection\n","        self.convA = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same', name=name + '_convA')\n","        self.reluA = LeakyReLU(alpha=0.2)\n","        self.convB = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same', name=name + '_convB')\n","        self.reluB = LeakyReLU(alpha=0.2)\n","\n","    def call(self, x):\n","        b = self.reluB(self.convB(self.reluA(self.convA(self.concat([self.up(x[0]), x[1]])))))\n","        return b\n","\n","\n","class Encoder(Model):\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","        self.base_model = DenseNet169(input_shape=(None, None, 3), include_top=False, weights='imagenet')\n","        print('Base model loaded {}'.format(DenseNet169.__name__))\n","\n","        # Create encoder model that produce final features along with multiple intermediate features\n","        outputs = [self.base_model.outputs[-1]]\n","        for name in ['pool1', 'pool2_pool', 'pool3_pool', 'conv1/relu']: outputs.append(\n","            self.base_model.get_layer(name).output)\n","        self.encoder = Model(inputs=self.base_model.inputs, outputs=outputs)\n","\n","    def call(self, x: list):\n","        return self.encoder(x)\n","\n","\n","class Decoder(Model):\n","    def __init__(self, decode_filters: int):\n","        super(Decoder, self).__init__()\n","        self.conv2 = Conv2D(filters=decode_filters, kernel_size=1, padding='same', name='conv2')\n","        self.up1 = UpscaleBlock(filters=decode_filters // 2, name='up1')\n","        self.up2 = UpscaleBlock(filters=decode_filters // 4, name='up2')\n","        self.up3 = UpscaleBlock(filters=decode_filters // 8, name='up3')\n","        self.up4 = UpscaleBlock(filters=decode_filters // 16, name='up4')\n","        self.conv3 = Conv2D(filters=1, kernel_size=3, strides=1, padding='same', name='conv3')\n","\n","    def call(self, features: list):\n","        x, pool1, pool2, pool3, conv1 = features[0], features[1], features[2], features[3], features[4]\n","        up0 = self.conv2(x)\n","        up1 = self.up1([up0, pool3])\n","        up2 = self.up2([up1, pool2])\n","        up3 = self.up3([up2, pool1])\n","        up4 = self.up4([up3, conv1])\n","        return self.conv3(up4)\n","\n","\n","class DepthEstimate(Model):\n","    def __init__(self):\n","        super(DepthEstimate, self).__init__()\n","        self.encoder = Encoder()\n","        self.decoder = Decoder(decode_filters=int(self.encoder.layers[-1].output[0].shape[-1] // 2))\n","        print('\\nModel created.')\n","\n","    def call(self, x):\n","        return self.decoder(self.encoder(x))\n","\n"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D8RyWG79gXQK"},"source":["## Loss Function ##"]},{"cell_type":"code","metadata":{"id":"SDsGVu8tf1p-","executionInfo":{"status":"ok","timestamp":1620239022837,"user_tz":240,"elapsed":973,"user":{"displayName":"STANISLAV SOTNIKOV","photoUrl":"","userId":"10330785928170966351"}}},"source":["def depth_loss_function(y_true, y_pred, theta=0.1, maxDepthVal=1000.0 / 10.0):\n","    # Point-wise depth\n","    l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)\n","\n","    # Edges\n","    dy_true, dx_true = tf.image.image_gradients(y_true)\n","    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n","    l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\n","\n","    # Structural similarity (SSIM) index\n","    l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, maxDepthVal)) * 0.5, 0, 1)\n","\n","    # Weights\n","    w1 = 1.0\n","    w2 = 1.0\n","    w3 = theta\n","\n","    return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oIJxdbHCivbD"},"source":["## Data Loaders ##"]},{"cell_type":"code","metadata":{"id":"CO7h1oUUn0Sr","executionInfo":{"status":"ok","timestamp":1620239022840,"user_tz":240,"elapsed":973,"user":{"displayName":"STANISLAV SOTNIKOV","photoUrl":"","userId":"10330785928170966351"}}},"source":["from zipfile import ZipFile\n","from PIL import Image"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvDOF9M0iu-F","executionInfo":{"status":"ok","timestamp":1620239022842,"user_tz":240,"elapsed":972,"user":{"displayName":"STANISLAV SOTNIKOV","photoUrl":"","userId":"10330785928170966351"}}},"source":["# Path to nyu depth dataset root directory.\n","def extract_zip(input_zip: str):\n","    input_zip=ZipFile(input_zip)\n","    return {name: input_zip.read(name) for name in input_zip.namelist()}\n","\n","def nyu_resize(img, resolution=480, padding=6):\n","    from skimage.transform import resize\n","    return resize(img, (resolution, int(resolution*4/3)), preserve_range=True, mode='reflect', anti_aliasing=True )\n","\n","def get_nyu_data(batch_size, nyu_data_zipfile='/home/slava/downloads/nyu_data.zip'):\n","    data = extract_zip(nyu_data_zipfile)\n","\n","    nyu2_train = list((row.split(',') for row in (data['data/nyu2_train.csv']).decode(\"utf-8\").split('\\n') if len(row) > 0))\n","    nyu2_test = list((row.split(',') for row in (data['data/nyu2_test.csv']).decode(\"utf-8\").split('\\n') if len(row) > 0))\n","\n","    shape_rgb = (batch_size, 480, 640, 3)\n","    shape_depth = (batch_size, 240, 320, 1)\n","\n","    # Helpful for testing...\n","    if False:\n","        nyu2_train = nyu2_train[:10]\n","        nyu2_test = nyu2_test[:10]\n","\n","    return data, nyu2_train, nyu2_test, shape_rgb, shape_depth\n","\n","def get_nyu_train_test_data(batch_size):\n","    data, nyu2_train, nyu2_test, shape_rgb, shape_depth = get_nyu_data(batch_size)\n","\n","    train_generator = NYU_BasicAugmentRGBSequence(data, nyu2_train, batch_size=batch_size, shape_rgb=shape_rgb, shape_depth=shape_depth)\n","    test_generator = NYU_BasicRGBSequence(data, nyu2_test, batch_size=batch_size, shape_rgb=shape_rgb, shape_depth=shape_depth)\n","\n","    return train_generator, test_generator\n","\n","class NYU_BasicAugmentRGBSequence(tf.keras.utils.Sequence):\n","    def __init__(self, data, dataset, batch_size, shape_rgb, shape_depth, is_flip=False, is_addnoise=False, is_erase=False):\n","        self.data = data\n","        self.dataset = dataset\n","        # self.policy = BasicPolicy( color_change_ratio=0.50, mirror_ratio=0.50, flip_ratio=0.0 if not is_flip else 0.2, \n","        #                             add_noise_peak=0 if not is_addnoise else 20, erase_ratio=-1.0 if not is_erase else 0.5)\n","        self.batch_size = batch_size\n","        self.shape_rgb = shape_rgb\n","        self.shape_depth = shape_depth\n","        self.maxDepth = 1000.0\n","\n","        from sklearn.utils import shuffle\n","        self.dataset = shuffle(self.dataset, random_state=0)\n","\n","        self.N = len(self.dataset)\n","\n","    def __len__(self):\n","        return int(np.ceil(self.N / float(self.batch_size)))\n","\n","    def __getitem__(self, idx, is_apply_policy=True):\n","        batch_x, batch_y = np.zeros( self.shape_rgb ), np.zeros( self.shape_depth )\n","\n","        # Augmentation of RGB images\n","        for i in range(batch_x.shape[0]):\n","            index = min((idx * self.batch_size) + i, self.N-1)\n","\n","            sample = self.dataset[index]\n","\n","            x = np.clip(np.asarray(Image.open( BytesIO(self.data[sample[0]]) )).reshape(480,640,3)/255,0,1)\n","            y = np.clip(np.asarray(Image.open( BytesIO(self.data[sample[1]]) )).reshape(480,640,1)/255*self.maxDepth,0,self.maxDepth)\n","            y = DepthNorm(y, maxDepth=self.maxDepth)\n","\n","            batch_x[i] = nyu_resize(x, 480)\n","            batch_y[i] = nyu_resize(y, 240)\n","\n","            # if is_apply_policy: batch_x[i], batch_y[i] = self.policy(batch_x[i], batch_y[i])\n","\n","        return batch_x, batch_y\n","\n","class NYU_BasicRGBSequence(tf.keras.utils.Sequence):\n","    def __init__(self, data, dataset, batch_size,shape_rgb, shape_depth):\n","        self.data = data\n","        self.dataset = dataset\n","        self.batch_size = batch_size\n","        self.N = len(self.dataset)\n","        self.shape_rgb = shape_rgb\n","        self.shape_depth = shape_depth\n","        self.maxDepth = 1000.0\n","\n","    def __len__(self):\n","        return int(np.ceil(self.N / float(self.batch_size)))\n","\n","    def __getitem__(self, idx):\n","        batch_x, batch_y = np.zeros( self.shape_rgb ), np.zeros( self.shape_depth )\n","        for i in range(self.batch_size):            \n","            index = min((idx * self.batch_size) + i, self.N-1)\n","\n","            sample = self.dataset[index]\n","\n","            x = np.clip(np.asarray(Image.open( BytesIO(self.data[sample[0]]))).reshape(480,640,3)/255,0,1)\n","            y = np.asarray(Image.open(BytesIO(self.data[sample[1]])), dtype=np.float32).reshape(480,640,1).copy().astype(float) / 10.0\n","            y = DepthNorm(y, maxDepth=self.maxDepth)\n","\n","            batch_x[i] = nyu_resize(x, 480)\n","            batch_y[i] = nyu_resize(y, 240)\n","\n","        return batch_x, batch_y\n","\n","def get_nyu_train_test_data(batch_size):\n","    data, nyu2_train, nyu2_test, shape_rgb, shape_depth = get_nyu_data(batch_size)\n","\n","    train_generator = NYU_BasicAugmentRGBSequence(data, nyu2_train, batch_size=batch_size, shape_rgb=shape_rgb, shape_depth=shape_depth)\n","    test_generator = NYU_BasicRGBSequence(data, nyu2_test, batch_size=batch_size, shape_rgb=shape_rgb, shape_depth=shape_depth)\n","\n","    return train_generator, test_generator"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"866XzE2mogkB"},"source":["## Train ##"]},{"cell_type":"markdown","metadata":{"id":"DvHfzt4YxnLU"},"source":["To get cuda working:\n"," - Install latest [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads)\n"," - Install latest [Cudnn library](https://developer.nvidia.com/cudnn)\n"," - Specify path to libcudnn \n"," ```shell\n"," export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64\n"," ```\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UuozUh8OokYF","executionInfo":{"status":"ok","timestamp":1620239026801,"user_tz":240,"elapsed":4928,"user":{"displayName":"STANISLAV SOTNIKOV","photoUrl":"","userId":"10330785928170966351"}},"outputId":"ec12974a-af8f-4821-f19b-c6e1e0f1ff4c"},"source":["model = DepthEstimate()\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Base model loaded DenseNet169\n","\n","Model created.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"id":"tSWFSAJFo-tj","executionInfo":{"status":"error","timestamp":1620239044063,"user_tz":240,"elapsed":22184,"user":{"displayName":"STANISLAV SOTNIKOV","photoUrl":"","userId":"10330785928170966351"}},"outputId":"88f0ecb8-cbca-4c3a-a749-96dec4862a19"},"source":["train_generator, test_generator = get_nyu_train_test_data(32)"],"execution_count":7,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-a6c8052afd87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nyu_train_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-0303e94c9939>\u001b[0m in \u001b[0;36mget_nyu_train_test_data\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnyu2_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnyu2_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nyu_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNYU_BasicAugmentRGBSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnyu2_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_rgb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mtest_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNYU_BasicRGBSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnyu2_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_rgb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-0303e94c9939>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, batch_size, shape_rgb, shape_depth, is_flip, is_addnoise, is_erase)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         self.policy = BasicPolicy( color_change_ratio=0.50, mirror_ratio=0.50, flip_ratio=0.0 if not is_flip else 0.2, \n\u001b[0m\u001b[1;32m     39\u001b[0m                                     add_noise_peak=0 if not is_addnoise else 20, erase_ratio=-1.0 if not is_erase else 0.5)\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'BasicPolicy' is not defined"]}]}]}